# ğŸ“˜ Hadoop HDFS Programming Lab  
*A Complete Step-by-Step Guide*

This document explains how to build, package, and run Java applications that interact with **HDFS** inside a Hadoop **Docker cluster**.  
It is written in clear and universal Markdown that any student can follow.

---

## ğŸ§© Table of Contents

1. [Prerequisites](#-prerequisites)  
2. [Docker Hadoop Environment](#-docker-hadoop-environment)  
3. [Start the Hadoop Cluster](#ï¸-start-the-hadoop-cluster)  
4. [Java Project Structure](#-java-project-structure)  
5. [Compile Using Maven](#-compile-using-maven)  
6. [Build Executable JAR Files](#-build-executable-jar-files)  
7. [Copy JARs to Shared Folder](#-copy-jars-to-shared-folder)  
8. [Enter the Hadoop Container](#ï¸-enter-the-hadoop-container)  
9. [Start Hadoop Services](#-start-hadoop-services)  
10. [Upload Input File to HDFS](#-upload-input-file-to-hdfs)  
11. [Run Java Programs on Hadoop](#-run-java-programs-on-hadoop)  
12. [Download Files from HDFS](#-download-files-from-hdfs)  
13. [Useful HDFS Commands](#-useful-hdfs-commands)  
14. [Summary](#-summary)

---

## ğŸ“¦ Prerequisites

Ensure the following tools are installed:

- **Ubuntu / Linux**
- **Docker & Docker Compose**
- **Java JDK 8**
- **Maven 3+**
- A text editor (VSCode recommended)

---

## ğŸ³ Docker Hadoop Environment

Your `docker-compose.yml` should map a shared folder:

```yaml
volumes:
  - ./hadoop_project:/shared_volume
This gives:

Host path	Container path
./hadoop_project	/shared_volume

Create your shared folder:

bash
Copier le code
mkdir -p hadoop_project
â–¶ï¸ Start the Hadoop Cluster
In the same folder as docker-compose.yml:

bash
Copier le code
docker compose up -d
Verify containers:

bash
Copier le code
docker ps
ğŸ§± Java Project Structure
Standard Maven structure:

swift
Copier le code
lab1/
 â”œâ”€â”€ pom.xml
 â””â”€â”€ src/
     â”œâ”€â”€ main/java/edu/supmti/hadoop/
     â”‚     â”œâ”€â”€ HadoopFileStatus.java
     â”‚     â”œâ”€â”€ ReadHDFS.java
     â”‚     â””â”€â”€ WriteHDFS.java
     â””â”€â”€ test/java/edu/supmti/hadoop/
           â””â”€â”€ (remove AppTest.java if unused)
ğŸ›  Compile Using Maven
Inside your project:

bash
Copier le code
mvn clean package
Output classes go to:

bash
Copier le code
target/classes/
ğŸ· Build Executable JAR Files
Each Java file needs a JAR with a manifest.

1ï¸âƒ£ HadoopFileStatus.jar
bash
Copier le code
echo "Main-Class: edu.supmti.hadoop.HadoopFileStatus" > manifest_hfs.txt
jar cfm target/HadoopFileStatus.jar manifest_hfs.txt -C target/classes .
2ï¸âƒ£ ReadHDFS.jar
bash
Copier le code
echo "Main-Class: edu.supmti.hadoop.ReadHDFS" > manifest_read.txt
jar cfm target/ReadHDFS.jar manifest_read.txt -C target/classes .
3ï¸âƒ£ WriteHDFS.jar
bash
Copier le code
echo "Main-Class: edu.supmti.hadoop.WriteHDFS" > manifest_write.txt
jar cfm target/WriteHDFS.jar manifest_write.txt -C target/classes .
ğŸ“¤ Copy JARs to Shared Folder
bash
Copier le code
cp target/*.jar hadoop_project/
Check:

bash
Copier le code
ls hadoop_project
ğŸ–¥ï¸ Enter the Hadoop Container
bash
Copier le code
docker exec -it hadoop-master bash
âš™ Start Hadoop Services
Inside the container:

bash
Copier le code
start-dfs.sh
start-yarn.sh
Check running services:

bash
Copier le code
jps
You should see:

NameNode

DataNode

ResourceManager

NodeManager

SecondaryNameNode

ğŸ“ Upload Input File to HDFS
Create input directory:

bash
Copier le code
hdfs dfs -mkdir -p /user/root/input
Upload input file:

bash
Copier le code
hdfs dfs -put -f /shared_volume/purchases.txt /user/root/input/
Verify:

bash
Copier le code
hdfs dfs -ls /user/root/input
ğŸš€ Run Java Programs on Hadoop
1ï¸âƒ£ HadoopFileStatus â€” rename file + show metadata
bash
Copier le code
hadoop jar /shared_volume/HadoopFileStatus.jar /user/root/input purchases.txt achats.txt
2ï¸âƒ£ ReadHDFS â€” display file content
bash
Copier le code
hadoop jar /shared_volume/ReadHDFS.jar /user/root/input/achats.txt
3ï¸âƒ£ WriteHDFS â€” write text into HDFS
bash
Copier le code
hadoop jar /shared_volume/WriteHDFS.jar /user/root/input/msg.txt "Hello from Hadoop!"
Display the file:

bash
Copier le code
hdfs dfs -cat /user/root/input/msg.txt
ğŸ“¥ Download Files from HDFS
Inside the container:

bash
Copier le code
hdfs dfs -get /user/root/input/achats.txt /shared_volume/achats_local.txt
Then on host:

bash
Copier le code
ls hadoop_project/
ğŸ§¹ Useful HDFS Commands
Action	Command
List root	hdfs dfs -ls /
Upload file	hdfs dfs -put local.txt /user/root/
Read file	hdfs dfs -cat /path/file.txt
Remove file	hdfs dfs -rm /path/file.txt
Remove folder	hdfs dfs -rm -r /path

ğŸ“ Summary
âœ” Start the Docker Hadoop cluster
âœ” Compile Java project with Maven
âœ” Create executable JAR files
âœ” Copy JARs to shared folder
âœ” Start Hadoop inside container
âœ” Upload files to HDFS
âœ” Run the 3 Hadoop Java programs
âœ” Download results back to host